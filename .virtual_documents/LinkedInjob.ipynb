#Import Packages
from selenium import webdriver
import time
import pandas as pd
import os
import itertools


#Import Packages

from selenium.webdriver.support.select import Select
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC


url1='https://www.linkedin.com/jobs/search?keywords=Marketing%20Data%20Analyst&location=Hyderabad%2C%20Telangana%2C%20India&geoId=105556991&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0'


driver = webdriver.Chrome()
driver.implicitly_wait(10)
driver.get(url1)


y=driver.find_elements(By.CLASS_NAME, 'results-context-header__job-count')[0].text



type(y)


n=pd.to_numeric(y)


n


i = 2
while i <= int((n + 200) / 25) + 1:
    try:
        # Scroll to the bottom of the page
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        i += 1

        # Find buttons with the text "See more jobs"
        buu = driver.find_elements(By.TAG_NAME, "button")
        x = [btn for btn in buu if btn.text == "See more jobs"]

        # Click each "See more jobs" button
        for btn in x:
            driver.execute_script("arguments[0].click();", btn)
            time.sleep(3)

    except Exception as e:
        print(f"An error occurred: {e}")
        time.sleep(4)





companyname= []
titlename= []


from selenium.webdriver.common.by import By

companyname = []  

try:
    # Find all elements with the specified class name
    companies = driver.find_elements(By.CLASS_NAME, 'base-search-card__subtitle')

    # Loop through the elements and extract text
    for company in companies:
        companyname.append(company.text)

except IndexError:
    print("IndexError occurred")





    len(companyname)



from selenium.webdriver.common.by import By

titlename = []  

try:
    # Find all elements with the specified class name
    titles = driver.find_elements(By.CLASS_NAME, 'base-search-card__title')

    # Loop through the elements and extract text
    for title in titles:
        titlename.append(title.text)

except IndexError:
    print("IndexError occurred")




len(titlename)



companyfinal=pd.DataFrame(companyname,columns=["company"])
titlefinal=pd.DataFrame(titlename,columns=["title"])


x=companyfinal.join(titlefinal)


x



jobList = driver.find_elements(By.CLASS_NAME, 'base-card__full-link')
hrefList = []
for e in jobList:
    hrefList.append(e.get_attribute('href'))

#for href in hrefList:
    #link.append(href)


linklist=pd.DataFrame(hrefList,columns=["joblinks"])



linklist.to_csv('linkedinlinks.csv')


result_df = pd.merge(companyfinal, titlefinal, left_index=True, right_index=True)
result_df = pd.merge(result_df, linklist, left_index=True, right_index=True)

# Save the result DataFrame to a CSV file
result_df.to_csv('output.csv', index=False)



driver.close()


pip install --upgrade jupyterlab jupyterlab-git

